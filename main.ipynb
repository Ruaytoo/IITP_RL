{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: \n",
    "    print(\"install lightning\")\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "DATASET_PATH = \"data\"\n",
    "CHECKPOINT_PATH = \"saved_models\"\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial11/\"\n",
    "pretrained_files = [\"MNISTFlow_simple.ckpt\", \"MNISTFlow_vardeq.ckpt\", \"MNISTFlow_multiscale.ckpt\"]\n",
    "\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(sample):\n",
    "    return (sample * 255).to(torch.int32)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                discretize])\n",
    "\n",
    "train_dataset = MNIST(root=DATASET_PATH, train=True, transform=transform, download=True)\n",
    "pl.seed_everything(42)\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [50000, 10000])\n",
    "\n",
    "test_set = MNIST(root=DATASET_PATH, train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = data.DataLoader(train_set, batch_size=256, shuffle=False, drop_last=False)\n",
    "val_loader = data.DataLoader(val_set, batch_size=64, shuffle=False, drop_last=False, num_workers=4)\n",
    "test_loader = data.DataLoader(test_set, batch_size=64, shuffle=False, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_imgs([train_set[i][0] for i in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42)\n",
    "orig_img = train_set[0][0].unsqueeze(dim=0)\n",
    "ldj = torch.zeros(1,)\n",
    "dequant_module = Dequantization()\n",
    "deq_img, ldj = dequant_module(orig_img, ldj, reverse=False)\n",
    "reconst_img, ldj = dequant_module(deq_img, ldj, reverse=True)\n",
    "\n",
    "d1, d2 = torch.where(orig_img.squeeze() != reconst_img.squeeze())\n",
    "if len(d1) != 0:\n",
    "    print(\"Dequantization was not invertible.\")\n",
    "    for i in range(d1.shape[0]):\n",
    "        print(\"Original value:\", orig_img[0,0,d1[i], d2[i]].item())\n",
    "        print(\"Reconstructed value:\", reconst_img[0,0,d1[i], d2[i]].item())\n",
    "else:\n",
    "    print(\"Successfully inverted dequantization\")\n",
    "\n",
    "visualize_dequantization(quants=8)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
